\documentclass[acmsmall,review]{acmart}
\settopmatter{printfolios=true,printccs=false,printacmref=false}

\usepackage{cmll}
\usepackage{mathpartir}

\newcommand{\tmRec}{\mathrm{rec}}
\newcommand{\tyNat}{\mathrm{Nat}}
\newcommand{\conZero}{\mathsf{zero}}
\newcommand{\conSucc}{\mathsf{succ}}
\newcommand{\conRefl}{\mathsf{refl}}

\newcommand{\Let}{\mathrm{let}}
\newcommand{\LetPair}{\mathrm{letpair}}
\newcommand{\In}{\mathrm{in}}
\newcommand{\If}{\mathrm{if}}
\newcommand{\dupNat}{\mathrm{dupNat}}

\newcommand{\istype}{\mathrm{type}}
\newcommand{\isctxt}{\mathrm{ctxt}}

\newcommand{\natinf}{\mathbb{N}_{-\infty}}

\newcommand{\Ty}{\mathrm{Ty}}
\newcommand{\RTm}{\mathrm{RTm}}
\newcommand{\Tm}{\mathrm{Tm}}

\newcommand{\Set}{\mathrm{Set}}

\newcommand{\cat}[1]{\mathcal{#1}}
\newcommand{\op}{\mathsf{op}}

\newcommand{\LinPoset}{\mathrm{LinPoset}}

\newcommand{\bob}[1]{\textcolor{purple}{FIXME: #1}}

%% Rights management information.  This information is sent to you
%% when you complete the rights form.  These commands have SAMPLE
%% values in them; it is your responsibility as an author to replace
%% the commands and values with those provided to you when you
%% complete the rights form.
\setcopyright{acmcopyright}
\copyrightyear{2020}
\acmYear{2020}
\acmDOI{10.1145/1122445.1122456}


%%
%% These commands are for a JOURNAL article.
\acmJournal{PACMPL}
\acmVolume{1}
\acmNumber{CONF}
\acmArticle{1}
\acmMonth{8}

%%
%% Submission ID.
%% Use this when submitting an article to a sponsored event. You'll
%% receive a unique submission ID from the organizers
%% of the event, and this ID should be used as the parameter to this command.
%%\acmSubmissionID{123-A56-BU3}

%%
%% The majority of ACM publications use numbered citations and
%% references.  The command \citestyle{authoryear} switches to the
%% "author year" style.
%%
%% If you are preparing content for an event
%% sponsored by ACM SIGGRAPH, you must use the "author year" style of
%% citations and references.
%% Uncommenting
%% the next command will enable that style.
%%\citestyle{acmauthoryear}

%%
%% end of the preamble, start of the body of the document source.
\begin{document}

%%
%% The "title" command has an optional parameter,
%% allowing the author to define a "short title" to be used in page headers.
\title{Polynomial Time and Full Dependent Types}

%%
%% The "author" command and its associated commands are used to define
%% the authors and their affiliations.
%% Of note is the shared affiliation of the first two authors, and the
%% "authornote" and "authornotemark" commands
%% used to denote shared contribution to the research.
\author{Robert Atkey}
\email{robert.atkey@strath.ac.uk}
\orcid{1234-5678-9012}
\affiliation{%
  \institution{University of Strathclyde}
  \streetaddress{26 Richmond Street}
  \city{Glasgow}
  \country{UK}
  \postcode{G1 1XH}
}


%%
%% By default, the full list of authors will be used in the page
%% headers. Often, this list is too long, and will overlap
%% other information printed in the page headers. This command allows
%% the author to define a more concise list
%% of authors' names for this purpose.
%\renewcommand{\shortauthors}{Trovato and Tobin, et al.}

%%
%% The abstract is a short summary of the work to be presented in the
%% article.
\begin{abstract}
  We combine dependent types for reasoning about programs with linear
  type systems for implicit polynomial time.
\end{abstract}

%%
%% The code below is generated by the tool at http://dl.acm.org/ccs.cfm.
%% Please copy and paste the code instead of the example below.
%%
\begin{CCSXML}
<ccs2012>
 <concept>
  <concept_id>10010520.10010553.10010562</concept_id>
  <concept_desc>Computer systems organization~Embedded systems</concept_desc>
  <concept_significance>500</concept_significance>
 </concept>
 <concept>
  <concept_id>10010520.10010575.10010755</concept_id>
  <concept_desc>Computer systems organization~Redundancy</concept_desc>
  <concept_significance>300</concept_significance>
 </concept>
 <concept>
  <concept_id>10010520.10010553.10010554</concept_id>
  <concept_desc>Computer systems organization~Robotics</concept_desc>
  <concept_significance>100</concept_significance>
 </concept>
 <concept>
  <concept_id>10003033.10003083.10003095</concept_id>
  <concept_desc>Networks~Network reliability</concept_desc>
  <concept_significance>100</concept_significance>
 </concept>
</ccs2012>
\end{CCSXML}

\ccsdesc[500]{Computer systems organization~Embedded systems}
\ccsdesc[300]{Computer systems organization~Redundancy}
\ccsdesc{Computer systems organization~Robotics}
\ccsdesc[100]{Networks~Network reliability}

%%
%% Keywords. The author(s) should pick words that accurately describe
%% the work being presented. Separate the keywords with commas.
\keywords{type theory, implicit computational complexity, linear types}


%%
%% This command processes the author and affiliation and title
%% information and builds the first part of the formatted document.
\maketitle

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Introduction}
\label{sec:introduction}

{\bf New story:}
\begin{enumerate}
\item Introduction: The goal of this paper is to unify implicit
  computational complexity with full dependent types. ICC enables us
  to ensure that \emph{programs} are within a certain complexity
  class, while dependent types allow us to state and prove that these
  programs solve the problems that we intend them to, and to construct
  reductions between problems. We can marry complexity-controlled
  implementations with problems, paving the way for a \emph{synthetic
    computational complexity theory}.
\item Section 1: Linear types and Implicit Polynomial Time.
  \begin{enumerate}
  \item Total typed functional programming, as we see in type theory,
    is restricted to the use of higher order functions and iteration
    over inductive data types.
  \item Polynomial time is the smallest class closed under nested
    iteration over the input -- i.e. we consider iteration over the
    input as feasible, and compositions thereof. The key thing is to
    avoid iteration over data constructed from the input.
  \item Key is to control iteration. So we split inductive datatypes
    into iterable and non-iterable versions. We can
  \item One way to capture polytime is to ensure that all iteration is
    only done over the input. So we can duplicate iterable things, but
    we can't construct new iterable things (at least not from an
    iteration). We also can't duplicate higher order things, because
    that effectively acts as a way to duplicate iterations (half
    instantiated iterators). Compare to Jones' CONS-FREE programming.
  \item Another approach is to allow ``borrowing'' of iterability by
    means of diamonds. Iterability becomes a first-class object, so we
    can use it to construct new data structures from the input. This
    allows the construction of new iterable data structures. LFPL.
  \end{enumerate}
\item Section 2: Extending to Dependent Types
  \begin{enumerate}
  \item Combining linear types and dependent types is subtle, because
    there is a fundamental incompatibility in the syntax of the two
    systems.
  \item There have been several approaches, though they are all
    somewhat similar (list them all here). We will use QTT, because it
    offers a firm semantic foundation as well as a relatively
    straightforward syntax.
  \item Recap the syntax of QTT, with extensional equality. Key point
    is that there is a normal dependently typed language with a linear
    sub-language. We can have special constructs in the linear
    sub-language that ``erase'' to normal type theory -- products are
    the prime example.
  \item Non iterable datatypes -- have normal eliminators in the DTT
    fragment, but
  \end{enumerate}
\item Section 3: Programming and Proving with Poly-time
  \begin{enumerate}
  \item Internalised completeness proofs.
  \item Construct the type of problems that are solvable in polynomial
    time.
  \item Construct reductions between problems.
  \item NP. Doesn't make sense to talk about this without dependent
    types, because we can't say when we've solved the problem being
    stated.
  \item PP (Probabilistic), using a monad. Again, need to be able to
    state connection with the problem to know that we are solving it.
  \end{enumerate}
\item Section 4: Soundness via Realisability
  \begin{enumerate}
  \item The underlying CBV language and its
  \end{enumerate}
\item Section 5: Extensions
  \begin{enumerate}
  \item Explicit Complexity via Diamond Counting
  \item Poly-time univalence
  \item Towards P- and NP-completeness proofs. Issue here is the
    extensionality. Towards a synthetic (poly-time based)
    computational complexity theory.
  \end{enumerate}
\item Section 6: Related Work
  \begin{enumerate}
  \item ICC stuff
    \begin{enumerate}
    \item LFPL
    \item CONS-free
    \item Soft Affine Logic; which has the same underlying idea as
      CONS-free (is this a novel observation?)
    \item Other systems based on information flow.
    \end{enumerate}
  \item Explicit complexity: lambda-amor, and things by Deepak Garg
    and Marco Gaboardi.
  \item Recent CMU stuff on calf
  \end{enumerate}

\end{enumerate}

{\bf Old story:}
\begin{enumerate}
\item There are systems for implicit computational complexity based on
  linear logic (e.g. LFPL, SAL, LLL, BLL) that seek to capture
  complexity classes (most often polynomial time) implicitly
  (i.e. without directly talking about time bounds). This work has
  also led to followup work on explicitly resourced calculi such as
  RAML, which seek to use static analysis to determine complexity
  bounds on programs.
\item In dependent type theory, we can reason about the extensional
  behaviour of programs (within the limits of intensional type
  theory), but not about intenstional properties. The only way to
  formalise something like ``for all polynomial time functions
  $\mathbb{N} \to \mathbb{N}$'' is to develop a deep emebdding of
  polynomial time functions and to work with that, which is tedious.
\item The goal of this paper is to unify dependent types for reasoning
  about programs with implicit computational complexity type
  systems. In the first instance, we do not seek to use dependent
  types to state precise bounds on programs' time consumption, but we
  intend to use dependent types to reason about the extensional
  behaviour of programs that we know to be polynomial time. At the end
  of the paper, we show how to adapt our framework to explicit
  resource accounting, in the style of RAML.
\item The plan of the paper is as follows:
  \begin{enumerate}
  \item We first introduction the ideas behind the use of linear logic
    for capturing polynomial time, by studying two systems Lafont's
    SAL, and Hofmann's LFPL. In Hofmann and Dal Lago's presentation,
    these are two variants of Second order Multiplicative Linear
    Logic, with restricted $\oc$ modalities for duplication. We also
    recall the realisability semantics of Dal Lago and Hofmann (FIXME:
    move this later?)
  \item The most modern presentations of these systems use second
    order quantification to represent data types. This is incompatible
    with the form of dependent types we use here, so we seek a direct
    representation of natural numbers that captures
  \item We then recall QTT, a extension of Martin-LÃ¶f type theory with
    linear types, which can accomodate intensional restrictions on
    computability as well as full reasoning about programs. Since
    allowing an unrestricted $\oc$ modality would violate our
    polynomial time bounds, we instead choose the natural number
    semiring for resource accounting.
  \item We then transplant the simply typed rules into QTT, showing
    how to carefully distinguish between data that is available to the
    program, and data that is only available for type formation.
  \item We finish by showing that we can also do explicit resource
    tracking.
  \end{enumerate}
\end{enumerate}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Linear $\lambda$-Calculus and Implicit Computational
  Complexity}
\label{sec:linear-icc}

Introduce the idea of linear typing for complexity control.

Linear $\lambda$-calculus, as we shall be discussing it in this
section:
\begin{mathpar}
  \inferrule* [right=Var]
  { }
  {x : A \vdash x : A}

  \inferrule* [right=Lam]
  {\Gamma, x : A \vdash M : B}
  {\Gamma \vdash \lambda x.M : A \multimap B}

  \inferrule* [right=App]
  {\Gamma_1 \vdash M : A \multimap B \\
    \Gamma_2 \vdash N : A}
  {\Gamma_1, \Gamma_2 \vdash M\,N : B}
\end{mathpar}

\begin{mathpar}
  \inferrule* [right=$\otimes$-Intro]
  {\Gamma_1 \vdash M : A \\ \Gamma_2 \vdash N : B}
  {\Gamma_1, \Gamma_2 \vdash (M,N) : A \otimes B}

  \inferrule* [right=$\otimes$-Elim]
  {\Gamma_1 \vdash M : A \otimes B \\ \Gamma_2, x : A, y : B \vdash N : C}
  {\Gamma_1, \Gamma_2 \vdash \Let\,(x,y)=M\,\In\,N : C}
\end{mathpar}

\subsection{Excluding Recursion}

What do we get if we exclude recursion altogether?

What happens if we include natural number recursion naively?

\paragraph{A Binary Tape Datatype}

FIXME: how to do this?

move left, move right, update. Tape is always finite.

\subsection{Cons-free programming}

FIXME: zero case has a context, or do we $\lambda$-abstract?
\begin{displaymath}
  \inferrule*
  {\vdash M_z : A \\ x : A \vdash M_s : A \\ \Gamma \vdash N : \tyNat}
  {\Gamma \vdash \tmRec\,N\,\{\conZero \mapsto M_z; \conSucc(x) \mapsto M_s\} : A}
\end{displaymath}

\begin{displaymath}
  \inferrule*
  {\Gamma \vdash M : \tyNat}
  {\Gamma \vdash \dupNat\,M : \tyNat \otimes \tyNat}
\end{displaymath}

Intuitive reason it works: we can only iterate over the natural
numbers we have recieved as input, there is no way to construct new
natural numbers by iteration. Duplicating natural numbers is safe,
becasue we can only do it a number of times controlled by iteration of
the natural numbers we are given.

FIXME: is it possible to pin down how it relates to SAL?

\paragraph{Completeness}

\begin{displaymath}
  \begin{array}{l}
    I_1 : \tyNat \multimap \mathit{St} \multimap \mathit{St} \\
    I_1 = \lambda n. \lambda s.\tmRec\,n\,\{\conZero \mapsto s; \conSucc(s) \mapsto f\,s \}
  \end{array}
\end{displaymath}

\begin{displaymath}
  \begin{array}{l}
    I_{k+1} : \tyNat \multimap \mathit{St} \multimap \mathit{St} \\
    I_{k+1} = \lambda n. \lambda s.
    \begin{array}[t]{@{}l}
      \Let\,(n,n') = \dupNat\,n\,\In\\
      \tmRec\,n\,\{\conZero \mapsto s; \conSucc(s) \mapsto I_k\,n'\,s \}
    \end{array}
  \end{array}
\end{displaymath}

\subsection{Diamond Trading with LFPL}

The cons-free style of programming allows us to express all polytime
Turing machines, but is quite awkward from the point of view of
functional programming. It allows us to iterate over natural numbers
that come from the input but does not allow us to build further values
to do iteration on. For example, if our input is a list, then we
cannot transform it into a binary search tree and then flatten it
\bob{actually write this}.

Introduce a new type $\Diamond$. Each $\Diamond$ value represents a
``chunk of iterability''.

{\bf Rough model:} programs are polynomials, data are bags of
diamonds. Applying a program to some data yields a concrete number of
steps that will bound the resulting computation.

\begin{mathpar}
  \inferrule*
  {\Gamma \vdash M : \Diamond}
  {\Gamma \vdash \conZero(M) : \tyNat}

  \inferrule*
  {\Gamma_1 \vdash M : \Diamond \\ \Gamma_2 \vdash N : \tyNat}
  {\Gamma_1, \Gamma_2 \vdash \conSucc(M, N) : \tyNat}
\end{mathpar}

\begin{displaymath}
  \inferrule*
  {d : \Diamond \vdash M_z : A \\ d : \Diamond, x : A \vdash M_s : A \\ \Gamma \vdash N : \tyNat}
  {\Gamma \vdash \tmRec\,N\,\{\conZero(d) \mapsto M_z; \conSucc(d,x) \mapsto M_s \} : A}
\end{displaymath}

\paragraph{Other datatypes} Trees, and so on.

\paragraph{Completeness for Polytime} We now show how every polytime
Turing machine can be simulated in LFPL with a non-iterable type of
tapes. The construction, due to Aelhig and Schwictenberg
\cite{syntactic-lfpl}, illustrates how programming with diamonds in
LFPL differs from the soft system in the previous section.

Assume a state type $\mathit{St}$ and a step function $f : \mathit{St} \multimap \mathit{St}$.

The linear iterator:
\begin{displaymath}
  \begin{array}{l}
    I_1 : (\tyNat \otimes \mathit{St}) \multimap (\tyNat \otimes \mathit{St}) \\
    I_1 = \lambda (n, s).\,\tmRec\,n\,\{
    \begin{array}[t]{@{}lcl}
      \conZero(d)&\mapsto&(\conZero(d), s);\\
      \conSucc(d,(n,s)) &\mapsto& (\conSucc(d,n),f\,s) \}
    \end{array}
  \end{array}
\end{displaymath}

Step:\textbf{Is the extra $f\,s$ required here?}
\begin{displaymath}
  \begin{array}{l}
    I_{k+1} : (\tyNat \otimes \mathit{St}) \multimap (\tyNat \otimes \mathit{St}) \\
    I_{k+1} = \lambda (n,s).\,\tmRec\,n\,\{
    \begin{array}[t]{@{}lcl}
      \conZero(d)&\mapsto&(\conZero(d),s); \\
      \conSucc(d,(n,s)) &\mapsto& \Let\,(n,s)=I_k\,(n,s)\,\In\,(\conSucc(d,n), f\,s) \}
    \end{array}
  \end{array}
\end{displaymath}

\begin{lemma}
  (Under a plausible operational semantics) FIXME: use an equational
  theory instead, that includes $\beta$-equality.
  \begin{displaymath}
    I_k\,(\underline{n},s) \longrightarrow^* (\underline{n},v)
  \end{displaymath}
  iff
  \begin{displaymath}
    f^{\binom{n}{k}}\,s \longrightarrow^* v
  \end{displaymath}
\end{lemma}


\subsection{Explicit Resource Tracking}

\begin{enumerate}
\item We still require diamonds to build zero and successor, but the
  iterator does not give them back.
\item In the simply typed case, we can annotate types with the static
  amount of potential they have per constructor.
\end{enumerate}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Complexity Control in Quantitative Type Theory}
\label{sec:qtt}

We have now seen three systems for controlling resource usage by means
of linear typing. We now look to extend these systems to include
dependent types. Our motivation is threefold:
\begin{enumerate}
\item We would like to have a means for reasoning about the behaviour
  of the programs we write in our systems. FIXME: why dependent types
  then? Why not a program logic?
\item In case of the explicitly resource accounted system, simple
  typing is limited in the reasoning the programmer can perform about
  the resources required by a particular program. While we could in
  principle
\item As well as constructing proofs \emph{about} complexity
  constrained programs, we would also be able to write constructive
  proofs that are themselves of constrained complexity.
\end{enumerate}

To integrate linear typing for controlling time complexity with
dependent types we use \emph{Quantitative Type Theory} (QTT)
\cite{atkey18qtt}. In this section, we review the definition of QTT
and how we have adapted it to implicit and explicit control of
computational complexity.

\begin{enumerate}
\item General description of QTT
\item Non-iterable datatypes in QTT
\item Adapting QTT to include a ``soft'' natural number type
\item Diamonds
\item
\end{enumerate}

\subsection{Quantitative Type Theory}

\begin{enumerate}
\item Rules for contexts (using $\epsilon$ for empty contexts to avoid
  confusion between $\diamond$ and $\Diamond$):
  \begin{mathpar}
    \inferrule* [right=Ctxt-Emp]
    { }
    {\epsilon~\isctxt}

    \inferrule* [right=Ctxt-Ext]
    {\Gamma~\isctxt \\ 0\Gamma \vdash S~\istype}
    {\Gamma, x \stackrel\rho: S~\isctxt}
  \end{mathpar}

  \begin{mathpar}
    \inferrule* [right=Tm-Var]
    {0\Gamma, x \stackrel\sigma: S, 0\Gamma'~\isctxt}
    {0\Gamma, x \stackrel\sigma: S, 0\Gamma' \vdash x \stackrel\sigma: S}

    \inferrule* [right=Tm-Conv]
    {\Gamma \vdash M \stackrel\sigma: S \\ 0\Gamma \vdash S \equiv T~\istype}
    {\Gamma \vdash M \stackrel\sigma: T}
  \end{mathpar}
\item Rules for $\Pi$ and $\Sigma$ types
  \begin{mathpar}
    \inferrule* [right=$\Pi$-type]
    {0\Gamma \vdash S~\istype \\ 0\Gamma, x \stackrel0: S \vdash T~\istype}
    {0\Gamma \vdash (x \stackrel\rho: S) \to T~\istype}

    \inferrule* [right=$\Pi$-Intro]
    {\Gamma, x \stackrel{\sigma\rho}: S \vdash M \stackrel\sigma: T}
    {\Gamma \vdash \lambda x.M \stackrel\sigma: (x \stackrel\rho: S) \to T}

    \inferrule* [right=$\Pi$-Elim]
    {\Gamma_1 \vdash M \stackrel\sigma: (x \stackrel\rho: S) \to T \\
      \Gamma_2 \vdash N \stackrel{\sigma'}: S \\
      FIXME}
    {\Gamma_1 + \rho\Gamma_2 \vdash M\,N \stackrel\sigma: T[N/x]}
  \end{mathpar}

  FIXME: $\Sigma$-types
\item Rules for equality
  \begin{mathpar}
    \inferrule* [right=Eq-type]
    {0\Gamma \vdash S~\istype \\
      0\Gamma \vdash M \stackrel0: S \\
      0\Gamma \vdash N \stackrel0: S}
    {0\Gamma \vdash M =_S N~\istype}

    \inferrule* [right=Eq-Intro]
    {\Gamma \vdash M \stackrel\sigma: S}
    {\Gamma \vdash \conRefl(M) \stackrel\sigma: M =_S M}
  \end{mathpar}
  \bob{Equality reflection?}
\item Rules for universe
\end{enumerate}

\subsection{Non-iterable Datatypes}

\subsection{Cons-free Natural Numbers}

Of course, ``cons-free'' only applies to the runtime portion of the
system. In the $\sigma = 0$ fragment, we are allowed to create new
natural numbers arbitrarily:
\begin{mathpar}
  \inferrule*
  {\Gamma \vdash}
  {\Gamma \vdash \conZero \stackrel0: \tyNat}

  \inferrule*
  {\Gamma \vdash M \stackrel0: \tyNat}
  {\Gamma \vdash \conSucc(M) \stackrel0: \tyNat}
\end{mathpar}
Creating numbers in the $\sigma = 0$ fragment ensures that we can talk
about natural numbers in our types, allowing us to state properties of
our programs.\bob{Forward ref to actually doing this.}

The eliminator:
\begin{displaymath}
  \mprset{flushleft}
  \inferrule*
  {0\Gamma, m \stackrel0: \tyNat \vdash X~\istype \\\\
    0\Gamma \vdash M_z \stackrel\sigma: X[\conZero/m] \\\\
    0\Gamma, n \stackrel0: \tyNat, x \stackrel1: X[n/m] \vdash M_s \stackrel\sigma: X[\conSucc(n)/m] \\\\
    \Gamma \vdash N \stackrel\sigma: \tyNat}
  {\Gamma \vdash \tmRec\,N\,\{\conZero \mapsto M_z; \conSucc(n/x) \mapsto M_s\} \stackrel\sigma: X[N/m]}
\end{displaymath}

\subsection{Diamonds}

\begin{mathpar}
  \inferrule* [right=DiaType]
  {\Gamma \vdash}
  {0\Gamma \vdash \Diamond~\istype}

  \inferrule* [right=DiaIntro]
  {\Gamma \vdash}
  {0\Gamma \vdash * \stackrel0: \Diamond}

  \inferrule* [right=DiaEta]
  {\Gamma \vdash M \stackrel0: \Diamond}
  {\Gamma \vdash M \equiv * \stackrel0: \Diamond}
\end{mathpar}

Link to Selinger et al: the $\eta$ rule for $\Diamond$s means that are
essentially depending on the ``shape'' of anything that depends on
diamonds.

\subsection{LFPL-style Natural Numbers}

\begin{mathpar}
  \inferrule*
  {\Gamma \vdash M \stackrel\sigma: \Diamond}
  {\Gamma \vdash \conZero(M) \stackrel\sigma: \tyNat}

  \inferrule*
  {\Gamma_1 \vdash M \stackrel\sigma: \Diamond \\
    \Gamma_2 \vdash N \stackrel\sigma: \tyNat \\
    0\Gamma_1 = 0\Gamma_2}
  {\Gamma_1 + \Gamma_2 \vdash \conSucc(M,N) \stackrel\sigma: \tyNat}
\end{mathpar}

\begin{mathpar}
  \mprset{flushleft}
  \inferrule*
  {0\Gamma, m \stackrel0: \tyNat \vdash X~\istype \\\\
    0\Gamma, d \stackrel1: \Diamond \vdash M_z \stackrel\sigma: X[\conZero(*)/m] \\\\
    0\Gamma, d \stackrel1: \Diamond, n \stackrel0: \tyNat, x \stackrel1: X[n/m] \vdash M_s \stackrel\sigma : X[\conSucc(*,n)/m] \\\\
    \Gamma \vdash N \stackrel\sigma: \tyNat}
  {\Gamma \vdash \tmRec\,N\,\{\conZero(d) \mapsto M_z; \conSucc(d,n/x) \mapsto M_s\} \stackrel\sigma: X[N/m]}
\end{mathpar}

Note: we have used $* : \Diamond$ as the value in the types for the
zero and successor cases. By the $\eta$-rule for diamonds, we could
have equally well used the $d$ variable that is in scope in each case.

\subsection{Explicit Potential}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Soundness via Realisability}
\label{sec:soundness}

\newcommand{\cstaccess}{c_{\mathit{access}}}
\newcommand{\cstmkclo}{c_{\mathit{mkclo}}}
\newcommand{\cstapp}{c_{\mathit{app}}}
\newcommand{\cstmkpair}{c_{\mathit{mkpair}}}
\newcommand{\cstmkunit}{c_{\mathit{mkunit}}}
\newcommand{\cstTrue}{c_{\mathit{mktrue}}}
\newcommand{\cstFalse}{c_{\mathit{mkfalse}}}
\newcommand{\cstLetpair}{c_{\mathit{letpair}}}
\newcommand{\cstSeq}{c_{\mathit{seq}}}
\newcommand{\cstIf}{c_{\mathit{if}}}

\newcommand{\clo}[2]{\mathsf{clo}\langle #1 , #2 \rangle}
\newcommand{\synTrue}{\mathsf{true}}
\newcommand{\synFalse}{\mathsf{false}}

\newcommand{\ExpSet}{\mathcal{E}}
\newcommand{\ValSet}{\mathcal{V}}

\newcommand{\rplus}{\oplus}
\newcommand{\rzero}{\emptyset}

FIXME: introductory paragraph.

The Hofmann-Dal Lago approach to proving the soundness of implicit
computational complexity systems is based on a three way coupling
between abstract mathematical elements (the \emph{what}), values from
a machine model (the \emph{how}), and resource potentials (the
\emph{fuel}). Each type in the system is defined as a three way
relation between these elements. The set of abstract elements depends
on the type being interpreted (e.g., types of natural numbers will be
defined in terms of the set $\mathbb{N}$). The machine model is fixed
across all types. We describe the particular machine model we use for
this paper in \autoref{sec:machine-model}. Potentials are arranged
into \emph{resource monoids} that we define in
\autoref{sec:resource-monoids}. Following Hofmann and Dal Lago, we
will select resource monoids appropriate to the kind of system that we
want to prove complexity soundness for.

\subsection{Machine Model and Operational Semantics}
\label{sec:machine-model}

\begin{figure}
  \centering
  {\bf Syntax}
  \begin{displaymath}
    \begin{array}{lcl}
      i,j &\in&\mathbb{N} \\
      E \in \ExpSet &::=& \lambda E \mid * \mid (i, j) \mid \synTrue \mid \synFalse \mid i \mid \Let\,E_1\,\In\,E_2 \mid i \cdot j \mid \LetPair\,i\,\In\,E \mid \If\,i\,E_1\,E_2 \\
      V \in \ValSet &::=& \clo{E}{\eta} \mid * \mid (V_1, V_2) \mid \synTrue \mid \synFalse \\
      \eta &::= & [] \mid \eta :: V
    \end{array}
  \end{displaymath}

  \vspace{1em}

  {\bf Evaluation: Construction}
  \begin{mathpar}
    \inferrule* [right=MkClo]
    { }
    {\lambda E , \eta \Downarrow_{\cstmkclo} \clo{E}{\eta}}

    \inferrule* [right=MkUnit]
    { }
    {*, \eta \Downarrow_{\cstmkunit} *}

    \inferrule* [right=MkPair]
    {\eta[i] = V_1 \\ \eta[j] = V_2}
    {(i, j), \eta \Downarrow_{\cstmkpair} (V_1, V_2)}

    \inferrule* [right=MkTrue]
    { }
    {\synTrue, \eta \Downarrow_{\cstTrue} \synTrue}

    \inferrule* [right=MkFalse]
    { }
    {\synFalse, \eta \Downarrow_{\cstFalse} \synFalse}
  \end{mathpar}

  \vspace{1em}

  {\bf Evaluation: Variable access and Sequencing}
  \begin{mathpar}
    \inferrule* [right=Access]
    {\eta[i] = v}
    {i, \eta \Downarrow_{\cstaccess} v}

    \inferrule* [right=Seq]
    {E_1, \eta \Downarrow_{k_1} V \\
      E_2, (\eta :: V) \Downarrow_{k_2} V'}
    {\Let\,E_1\,\In\,E_2, \eta \Downarrow_{k_1 + \cstSeq + k_2} V'}
  \end{mathpar}

  \vspace{1em}

  {\bf Evaluation: Elimination}
  \begin{mathpar}
    \inferrule* [right=App]
    {\eta[i] = \clo{E}{\eta'} \\
      \eta[j] = V \\
      E , (\eta' :: \clo{E}{\eta'} :: V) \Downarrow_k V'}
    {(i \cdot j), \eta \Downarrow_{\cstapp + k} V'}

    \inferrule* [right=LetPair]
    {\eta[i] = (V_1, V_2) \\
      E, (\eta :: V_1 :: V_2) \Downarrow_k V}
    {\LetPair\,i\,\In\,E, \eta \Downarrow_{\cstLetpair + k} V}

    \inferrule* [right=IfTrue]
    {\eta[i] = \synTrue \\ E_1, \eta \Downarrow_k V}
    {\If\,i\,E_1\,E_2, \eta \Downarrow_{\cstIf + k} V}

    \inferrule* [right=IfFalse]
    {\eta[i] = \synFalse \\ E_2, \eta \Downarrow_k V}
    {\If\,i\,E_1\,E_2, \eta \Downarrow_{\cstIf + k} V}
\end{mathpar}
  \caption{Language with Big-step Costed Evaluation Semantics}
  \label{fig:opsem}
\end{figure}

Note: the Agda formalisation is intrinsically well-scoped, which
makes expressing things a bit easier.

The syntax and rules of our target language are given in
\autoref{fig:opsem}.

\begin{enumerate}
\item Justification that looking up variables is constant: Due to
  lexical scoping, the size of the maximum variable lookup is bounded
  for a fixed program.
\item An advantage of our more ``elementary'' operational semantics
  (rather than encoding everything in the $\lambda$-calculus)
\end{enumerate}

\subsection{Resource Monoids}
\label{sec:resource-monoids}

Resource potentials are attached to values to represent the amount of
intrinsic potential they have to fuel computation. Resource potentials
are organised into resource monoids. To motivate the definition, we
first enumerate the structure we will. To be able to account for the
combined potential attached to composite data and programs (e.g.,
pairs, or functions applied to arguments) we will require monoid
structure on potentials. The action of turning potential difference
into fuel for computation will be modelled by a difference
function. Finally, we require that our resource monoid contains
sufficient elements to fuel constant time operations. We gather these
requirements into a formal definition as follows:

\begin{definition}
  A \emph{resource monoid} $M$ consists of:
  \begin{enumerate}
  \item A carrier set $|M|$, whose elements represent amounts of
    potential. We use Greek letters $\alpha$, $\beta$, $\gamma$ to
    denote elements of a resource monoid.
  \item Commutative monoid structure $(\rplus,\rzero)$ on $|M|$, so
    we can add potentials.
  \item A \emph{difference function} $M : |M| \times |M| \to \natinf$,
    where $\natinf$ is the natural numbers extended with a negative
    infinity $- \infty$ and $- \infty + k = -\infty$. A difference
    $M(\alpha, \beta) = k \in \mathbb{N}$ means that starting with
    potential $\alpha$ and ending with potential $\beta$ yields $k$
    units of fuel. A difference of $- \infty$ means that $\alpha$
    contains insufficient potential to reach $\beta$. Differencing
    must satisfy:
    \begin{enumerate}
    \item for all $\alpha$, $M(\alpha,\alpha) = 0$; and
    \item for all $\alpha, \beta, \gamma$,
      $M(\alpha, \beta) \rplus M(\beta, \gamma) \leq M(\alpha, \gamma)$.
    \end{enumerate}
    The latter is a ``reverse triangle inequality'': the fuel
    recoverable by moving between potential levels $\alpha$ and
    $\gamma$ via $\beta$ may be less than the fuel recoverable
    moving from $\alpha$ to $\gamma$ directly.
  \item \bob{Interaction between $(\rplus,\rzero)$ and $M(\alpha,\beta)$.}
  \item An \emph{accounting function}
    $\mathit{acct} : \mathbb{N} \to |M|$ such that for all $k$,
    $k \leq M(\mathit{acct}(k),\rzero)$.
  \end{enumerate}
\end{definition}

\subsubsection{Specific Resource Monoids}

The simplest example of a resource monoid is given by the natural
numbers $\mathbb{N}$, where each number stands directly an amount of
stored fuel.

\begin{definition}[Natural Number Resource Monoid]
  Monoid structure is given by normal addition. Differencing is
  defined as
  \begin{displaymath}
    \mathbb{N}(m,n) = \left\{
      \begin{array}{ll}
        m - n & m \geq n \\
        - \infty & \textrm{otherwise}
      \end{array}\right.
  \end{displaymath}
  and $\mathit{acct}(k) = k$. Note that this is the simplest possible
  resource monoid due to the requirement that the $\mathit{acct}$
  function exists. \bob{Forward ref to where this is used.}
\end{definition}

Every resource monoid induces a partial ordering on its carrier set by
$\alpha \leq \beta$ iff $0 \leq M(\alpha, \beta)$. In the case of the
natural number resource monoid, this yields the usual ordering on the
naturals.

\newcommand{\MaxPoly}{\mathrm{MaxPoly}}
\newcommand{\PlusPoly}{\mathrm{PlusPoly}}

The differencing operator of the natural number resource monoid can
only supply as much fuel as is contained in the potential. This makes
it suitable for amortised analysis, where we directly store potential
in data structures. For the two polynomial time systems, we need more
sophisticated structures originally presented by Dal Lago and
Hofmann. The fundamental idea with both is to represent potentials as
pairs $(m,p)$, where $m$ is a natural number and $p$ is a
polynomial. The $m$ tracks the ``size'' of data as it pertains to the
number of times an operation will be repeated by iterating over it ---
for example, an iterable natural number will have size equal to
itself, but a non-iterable natural number may be assigned zero
size. The polynomial $p$ tracks the complexity of a program as a
function of the size of the input. This leads to a differencing
operator that evaluates the polynomial with the size of the data:

\begin{definition}[Polynomial Resource Monoids]
  The \emph{Max-Polynomial} resource monoid $\MaxPoly$ has carrier
  set consisting of pairs $(m,p)$ where $m$ is natural number and $p$
  is a polynomial with natural number coefficients. Addition of
  elements is defined as $(m,p) \oplus (n,q) = (m \sqcup n, p+q)$ with
  $\emptyset = (0,0)$. Difference is defined as:
  \begin{displaymath}
    \MaxPoly((m,p),(n,q)) = \left\{
      \begin{array}{ll}
        p(m) - q(m)&m \geq n \textrm{ and } \forall k \geq m. p(k) \geq q(k) \\
        - \infty & \textrm{otherwise}
      \end{array}
    \right.
  \end{displaymath}
  $\MaxPoly$ accounts for constant time with constant polynomials:
  $\mathit{acct}(k) = (0,\lambda x.k)$.

  The \emph{Plus-Polynomial} resource monoid $\PlusPoly$ is defined
  the same way as $\MaxPoly$ except that the monoid addition adds the
  natural number components instead of taking their maximum:
  $(m,p) \oplus (n,q) = (m + n, p+q)$.
\end{definition}

It is perhaps easier to see how the differencing operator works in the
special case of the difference $\MaxPoly((m,p),(0,0)) = p(m)$. I.e.,
if we have code that contains data of size $m$ and a program with
complexity $p$, then running the combination with no expectation of
remaining potential yields $p(m)$ available steps.

The $\MaxPoly$ and $\PlusPoly$ resource monoids will be used for the
cons-free and LFPL-style (i.e., with diamonds) systems
respectively. We will elaborate on how in
\autoref{sec:realisability-model} and how they support the two kinds
of natural number iteration in \autoref{sec:realising-iteration}.

FIXME: difference between this definition and Hofmann-Dal Lago's: we
use polynomials with natural number coefficients instead of a function
that is bounded by a polynomial.

\subsubsection{Resource sub-monoids}

The separation between sizes of data and complexity of code in the
polynomial resource monoids motivates the use of resource sub-monoids
to ensure that programs themselves (as opposed to higher order code
which may contain closed over data) do not contain data that can be
iterated. We do this by requiring that programs' potential must come
from a specified resource sub-monoid:

\begin{definition}[Resource Sub-Monoids]
  A \emph{resource sub-monoid} $M_0 \subseteq M$ of a resource monoid
  $M$ consists of a subset $|M_0| \subseteq |M|$ that is closed under
  the monoid operations and $\mathit{acct}$.
\end{definition}

For both $\MaxPoly$ and $\PlusPoly$, the elements with zero size
component, i.e., of the form $(0,p)$, form a resource sub-monoid that
we will use for interpreting programs. We will call these sub-monoids
$\MaxPoly_0$ and $\PlusPoly_0$. We make use of resource sub-monoids
in our definitions of the interpretations of simultaneous
substitutions (\autoref{defn:rl-morphism}) and terms
(\autoref{defn:rl-terms}).

\subsubsection{Resource Monoids as Enriched Categories}

An alternative perspective on resource monoids is to see them as a
kind of entriched category \cite{kelly}. Enriched categories replace
the sets of morphisms between objects with objects from some category
other than $\Set$. Define the posetal category $\natinf$ with objects $\mathbb{N} \cup \{\infty\}$ and

$\natinf$ as a category.

\bob{remember to look at the Marsden and thingy paper about
  quantitative resources and enriched categories.}  A concise
definition of Hofmann and Dal Lago's resource monoids can be given as:
\begin{definition}
  A \emph{resource monoid} is a strict symmetric monoidal
  $\natinf$-enriched category.
\end{definition}

FIXME: Relational definition, used for the formalisation.

\subsection{Models of Quantitative Type Theory}
\label{sec:qtt-models}

\bob{PLAN: RCwFs, and state that they can be constructed from Indexed Linear Posets}

\cite{atkey18} describes a general class of QTT models termed
\emph{Quantitative Categories with Families} (QCwFs). This class of
models fits will with the syntax of QTT, but to actually build models
it is revealing to construct them from certain indexed partial orders,
as we explain now. In the next section, we will construct a class of
specific models that prove the soundness of our complexity constrained
systems.

\begin{definition}[Category with Families]
  BLAH
\end{definition}

\begin{definition}
  A \emph{linear poset} is a partially ordered set $(A, \leq)$ with
  \begin{enumerate}
  \item A commutative monoid $(I, -\otimes-)$ that is monotone
    w.r.t. the order; and
  \item Is closed: there is an operation
    $\multimap : A \times A \to A$ such that $x \otimes y \leq z$ iff
    $x \leq y \multimap z$.
  \end{enumerate}
  The collection of all linear posets and functions that preserve the
  order and the operations forms a category $\LinPoset$.
\end{definition}

\begin{definition}
  \begin{enumerate}
  \item A CwF $(\cat{C}, \top, \langle-,-\rangle, ...)$ that supports
    $\Pi$ and $\Sigma$ types.
  \item A functor $L : \cat{C}^\op \to \LinPoset$, such that
    reindexing along projections has a right adjoint:
    \begin{displaymath}
      L_{\Gamma.A}(\pi^*X, Y) \cong L_{\Gamma}(X, \forall_A Y)
    \end{displaymath}
  \end{enumerate}
\end{definition}

\bob{define the construction}
\begin{enumerate}
\item Start with a CwF $\cat{C}$ that supports $\Pi$, $\Sigma$ and
  natural numbers.
\item Assume a functor $L : \cat{C}^\top \to \LinPoset$ with
  reindexing along projections having a right adjoint.
\item Construct a new CwF with the same base category as $\cat{C}$,
  but with $\Ty'(\Delta) = \Sigma A : \Ty(\Delta).~L(\Delta.A)$ and
  $\Tm'(\Delta, (T, X)) = \Tm(\Delta, T)$.
\item
\end{enumerate}

This construction is implicit in \cite{atkey2018qtt}, where the
indexed linear poset is defined from a $\mathcal{R}$-LCA.


\subsection{Amortised Complexity Realisability Model}
\label{sec:realisability-model}

Equipped with our underlying costed model of computation
(\autoref{sec:machine-model}) and a compositional notion of resource
potential (\autoref{sec:resource-monoids}), we construct models of QTT
that witness the resource and type soundness of our complexity
constrained systems.

\bob{Tie back to previous section}

We fix a resource monoid $M$ with distinguished sub-monoid $M_0$.

\subsubsection{Base CwF}
\label{sec:realisability-base-cwf}

As our base CwF, we use the category $\Set$ of sets and functions with
the standard interpretation of $\Pi$, $\Sigma$ types and the
$\mathbb{N}$ type.

\subsubsection{Indexed Linear Preorder}
\label{sec:realisability-indexed-linear-preorder}

We now define an indexed linear poset $L$ of realisers over $\Set$
that ties together our ``mathematical'' model of types in $\Set$ with
our machine model and resource monoid. For a set $A$, the carrier of
$L(A)$ is the set of ternary relations
$X \subseteq A \times M \times \ValSet$ and we define the ordering
$X \leq Y$ to hold iff there exists realising expression
$E \in \ExpSet$ and potential $\gamma \in M_0$ such that for all
$a \in A$, $\alpha \in M$ and $v \in \ValSet$ with
$(a,\alpha,v) \in X$, we have that there exists a result
$v' \in \ValSet$, step count $k \in \mathbb{N}$ and result potential
$\beta \in M$ with:
\begin{enumerate}
\item $E, v \Downarrow_k v'$ (evaluation successfully completes in $k$ steps);
\item $(a, \beta, v') \in Y$ (the result is well-resourced and
  satisfies $Y$); and
\item $k \leq M(\alpha \rplus \gamma, \beta)$ (the step count is within the
  difference between the initial potential and the result potential).
\end{enumerate}
Note that the definition of realisablity is uniform in the element $a$
-- the realising expression $e$ and the potential $\gamma$ must work
for all $a$ -- thus the implementation and complexity measure of the
transition being modelled cannot depend on what the input is. Put in
implementation terms, the input $a$ is not present at
runtime. Moreover note that the potential $\gamma$ attached to the
expression $e$ must come from the sub-monoid $M_0$, indicating that is
intended to be data-free, while the potential $\alpha$ for the input
is from the full monoid $M$, so it can contain data and functions.

For $X, Y \in L(A)$, the required elements for symmetric monoidal
closed structure are defined as follows. For the tensor product
$X \otimes Y \in L(A)$, the realising value must be a pair $(v_1,v_2)$
and the potential of the pair must split into suitable potentials
$\alpha_1$, $\alpha_2$ for the components. For the residual
$X \multimap Y$, the realising value must be a closure with potential
to, when added to the potential of an input, compute the output with
enough remaining. Note that the potential attached to a closure
($\alpha$, here) need not be from the sub-monoid $M_0$. Unlike
top-level term interpretations, closures may contain data.
\begin{displaymath}
  \begin{array}{lcl}
    X \otimes Y &=& \{ (a, \alpha, (v_1, v_2)) \mid \exists \alpha_1, \alpha_2.~0 \leq M(\alpha, \alpha_1 \rplus \alpha_2) \land X(a,\alpha_1,v_1) \land Y(a,\alpha_2,v_2) \}\\
    X \multimap Y &=& \{ (a, \alpha, \clo{E}{\eta}) \mid
                      \begin{array}[t]{@{}l}
                        \forall \alpha' \in M, v,w \in \ValSet.\,X(a,\alpha',v) \Rightarrow\\
                        \quad \exists v', k, \beta.\,
                        E, (\eta :: w :: v) \Downarrow_k v' \land Y(a,\beta,v') \land k \leq M(\alpha \rplus \alpha', \beta) \} \end{array}
  \end{array}
\end{displaymath}
The seemingly useless $w \in \ValSet$ in the formula for
$X \multimap Y$ is a dummy argument standing for the self-referential
reference to the closure used for defining recursive programs.

Each $L(A)$ has a terminal (i.e. top) element, which is also the unit
for $\otimes$, defined as
$I_A = \{(a, \alpha, *) \mid a \in A, \alpha \in M\}$. The potential
$\alpha$ here is unrestricted, so $I_A$ can consume an arbitrary
resource.

$\mathbb{N}$-Graded exponentials in each $L(A)$ are defined using the
action $(\cdot)$ of $(\mathbb{N}, \leq)$ on $M$ defined above \bob{do
  this}. At the level of realising values, the modality $\oc_n$ has no
effect; it only serves to alter the required potentials.
\begin{displaymath}
  \oc_n\,X = \{(a,\alpha,v) \mid \exists \alpha'.\,M(n \cdot \alpha', \alpha) = 0 \land (a, \alpha', v) \in X \}
\end{displaymath}

$L$ also has arbitrary $\Set$-indexed products, realised ``lazily'' as
functions that take dummy arguments. For $A \in \Set$ and
$B \in A \to \Set$ and $X \in L(\Sigma A.\,B)$, we define
$\forall_B X \in L(A)$ similarly to $\multimap$ above, but with
different resource and indexing requirements:
\begin{displaymath}
  \forall_B X = \{ (a,\alpha,\clo{E}{\eta}) \mid \forall b, v.~\exists v', \beta, k. E, (\eta :: v :: *) \Downarrow_k v' \land X((a,b),\beta,v') \land k \leq M(\alpha,\beta) \}
\end{displaymath}
Note, as with the definition of $X \leq Y$ above, the realiser closure
$\clo{E}{\eta}$ must be chosen uniformly for all $b$. This definition
also appears to allow arbitrary computation (paid for by $\alpha$) to
happen when the realising closure is applied, but the potential
$\alpha$ will only ever be greater than $\beta$ by enough to handle
the administrative costs of applying the function.

To complete the construction of $L$ as an indexed linear preorder, we
need to give realisers for each of the required inequalities in
\autoref{def:indexed-linear-preorder}. In each case, this is a matter
of programming in the language of \autoref{sec:machine-model}. The
corresponding potentials are calculated by counting the steps in the
ensuing programs. Note that, so far, all realisers are constant time
(relative to their input), so the constructions so far work for any
resource monoid. For systems that require iteration, we will need more
structure on our resource monoids \bob{fwd ref}.

\begin{proposition}
  $L$, with $I$, $\otimes$, $\multimap$, $\oc_n$, and $\forall_{B}$ defined above, is
  an indexed linear preorder.
\end{proposition}

\begin{proof}
  See the Agda development.
\end{proof}

\begin{proposition}\label{prop:basic-qtt-realisability-model}
  Get a model QTT with $\Pi$, $\Sigma$, and a universe.
\end{proposition}

\subsubsection{Non-iterable Data Types}

The model of QTT constructed in
\autoref{prop:basic-qtt-realisability-model} does not yet include any
useful base types. Handling iterable types, which are the ones that
induce non-constant-time complexities, requires specific properties of
resource monoids that we introduce in
\autoref{sec:realising-iteration}.

Rather than perform a complex generic construction of datatypes to
show how non-iterable versions may be realised, we focus on two
representative examples. Booleans

\paragraph{Booleans} Fix $\mathbb{B} = \{ \mathit{tt}, \mathit{ff} \}$
as our set of boolean elements. We define an element of $L(\mathbb{B}$
to represent boolean values:
\begin{displaymath}
  \mathrm{bool} = \{ (\mathit{tt}, \alpha, \synTrue) \mid \alpha \in M \} \cup \{ (\mathit{ff}, \alpha, \synFalse) \mid \alpha \in M \}
\end{displaymath}
Thus, the boolean $\mathit{tt}$ is represented by the value $\synTrue$
and $\mathit{ff}$ is represented by $\synFalse$. In both case, we
allow arbitrary potentials to be attached.



\paragraph{Lists}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Realising Iteration for Implicit Polynomial Time}
\label{sec:realising-iteration}

Explain why the polytime iterators work.

\begin{theorem}[Soundness for the Cons-free System]
  \label{thm:cons-free-soundness}
\end{theorem}

\begin{theorem}[Soundness for the LFPL-style System]
  \label{thm:lfpl-soundness}
\end{theorem}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Realising Explicit Amortised Complexity}
\label{sec:explicit-amortised-complexity}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Relationship to Second-order MALL with Modalities}
\label{sec:poly-mall}

\begin{enumerate}
\item Compare the SAL and LFPL modalities to the natural number
  constructions
  \begin{enumerate}
  \item In the SAL case, we have $\oc A \multimap A^n$, which allows
    us to
  \end{enumerate}
\end{enumerate}



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Programming in Polytime}
\label{sec:programming-polytime}

\begin{enumerate}
\item Non-deterministic polytime via a bit oracle -- needs a statement
  of success
\item Previous could also be interpreted as probabilistic polytime
  (access to coin flips); can we formalise some kind of cryptographic
  property this way? Have a look at hash functions in the
  Authenticated Data Structures paper.
\item Insertion sort, quicksort as polytime functions.
\item A type of polytime functions; via a reflection operator
\item Programming with explicit resource annotations, including
  reasoning about the resource requirements directly.
\end{enumerate}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Conclusion}
\label{sec:conclusion}

\begin{enumerate}
\item Brunel's classical quantitative realisability
\item Works on polytime realisability for proof extraction (Schwictenberg, Soft Set Theory)
\item Lower complexity classes, like LOGSPACE
\item Higher complexity classes, like EXPTIME, ELEMENTARY
\item More fine-granied classes, like PTIME($k$)
\item Automation, in the style of Jan's stuff
\item Circuits and shit.
\end{enumerate}


%%
%% The acknowledgments section is defined using the "acks" environment
%% (and NOT an unnumbered section). This ensures the proper
%% identification of the section in the article metadata, and the
%% consistent spelling of the heading.
\begin{acks}
  FIXME
\end{acks}

%%
%% The next two lines define the bibliography style to be used, and
%% the bibliography file.
\bibliographystyle{ACM-Reference-Format}
\bibliography{sample-base}


\end{document}
\endinput
